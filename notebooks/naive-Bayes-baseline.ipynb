{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayush/Documents/TAMU MS CS/Sem 1/NLP/semeval2023-afrisenti/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_and_labels(tsv_path):\n",
    "    df = pd.read_csv(tsv_path, sep='\\t')\n",
    "    data = df['tweet'].to_list()\n",
    "    labels = df['label'].to_list()\n",
    "    labels = [t.strip().upper() for t in labels]\n",
    "    return data, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "def get_features(corpus, vocab_size):\n",
    "    vectorizer = CountVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=vocab_size,\n",
    "        tokenizer=identity_tokenizer, # already receiving tokenized text from AUtotokenizer\n",
    "        lowercase=False,\n",
    "        token_pattern=None\n",
    "    )\n",
    "    vectorizer.fit(corpus)\n",
    "    X = vectorizer.transform(corpus)\n",
    "    return X, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kflod(data, true_labels, tokenizer):\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    tokenized_texts_str = [tokenizer.convert_ids_to_tokens(text) for text in tokenizer(data)['input_ids']]\n",
    "    features,_ = get_features(tokenized_texts_str, VOCAB_SIZE)\n",
    "    true_test_labels = []\n",
    "    predicted_test_labels = []\n",
    "    for train_index, test_index in skf.split(features, true_labels):\n",
    "        classifier = MultinomialNB()\n",
    "        train_labels = true_labels[train_index]\n",
    "        classifier.fit(features[train_index], train_labels)\n",
    "        train_predictions = classifier.predict(features[train_index])\n",
    "        test_predictions = classifier.predict(features[test_index])\n",
    "        test_labels = true_labels[test_index]\n",
    "        true_test_labels.extend(test_labels)\n",
    "        predicted_test_labels.extend(test_predictions)\n",
    "        # train_f1 = f1_score(train_labels, train_predictions, average='micro', labels=['NEGATIVE', 'NEUTRAL','POSITIVE'])\n",
    "        # test_f1 = f1_score(test_labels, test_predictions, average='micro', labels=['NEGATIVE', 'NEUTRAL','POSITIVE'])\n",
    "        # print(f\"Train F1: {train_f1}, Test F1: {test_f1}\")\n",
    "    return true_test_labels, predicted_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_and_dataset(data_set_path):\n",
    "    data_files = sorted(Path(data_set_path).glob('*.tsv'))\n",
    "    african_language_model = 'Davlan/afro-xlmr-mini'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(african_language_model)\n",
    "    results = []\n",
    "    for csv_file in tqdm(data_files, total=len(data_files)):\n",
    "        language = csv_file.stem.split('_')[0]\n",
    "        model = \"Multinomial Naive Bayes\"\n",
    "        data, true_labels = get_data_and_labels(csv_file)\n",
    "        label_set = ['NEGATIVE', 'POSITIVE', 'NEUTRAL']\n",
    "        true_labels, predicted_labels = evaluate_kflod(data, true_labels, tokenizer)\n",
    "        accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "        precision = precision_score(true_labels, predicted_labels, labels=label_set, average=None)\n",
    "        recall = recall_score(true_labels, predicted_labels, labels=label_set, average=None)\n",
    "        f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "        output = {  'model': model,\n",
    "                    'language': language,\n",
    "                    'num_examples': len(data),\n",
    "                    'precision': {label_set[i]: precision[i] for i in range(len(label_set))},\n",
    "                    'recall': {label_set[i]: recall[i] for i in range(len(label_set))},\n",
    "                    'f1_score_macro': f1,\n",
    "                    'accuracy': accuracy\n",
    "                }\n",
    "        results.append(output)\n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:10<00:00,  1.20s/it]\n"
     ]
    }
   ],
   "source": [
    "data_path = Path('../data/raw/train/')\n",
    "results = evaluate_model_and_dataset(data_path)\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel('../reports/multinomial_naive_bayes_evaluation.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15+"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee4d42a04b0712fbf42e410fdfe3da93f7c73adbc91ac583dc0801633f1f50b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
