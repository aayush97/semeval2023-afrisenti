{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc68558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "import evaluate\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForPreTraining,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    DataCollatorForWholeWordMask,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version, send_example_telemetry\n",
    "from transformers.utils.versions import require_version\n",
    "from datasets import Features, Value, ClassLabel, load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b799e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "require_version(\"datasets>=1.8.0\", \"To fix: pip install -r examples/pytorch/text-classification/requirements.txt\")\n",
    "LANGUAGE_CODE = \"am\"\n",
    "LEARNING_RATE = 5e-5\n",
    "EPOCHS=5\n",
    "MAX_SEQUENCE_LENGTH=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c868fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = f\"../models/{LANGUAGE_CODE}\"\n",
    "DATA_DIR = f\"../data/raw/language_model/{LANGUAGE_CODE}\"\n",
    "MODEL_NAME = f'Davlan/afro-xlmr-small'\n",
    "def finetune_lm():\n",
    "    training_args = TrainingArguments(output_dir=OUTPUT_DIR,\n",
    "                                      overwrite_output_dir=True,\n",
    "                                     do_train=True,\n",
    "#                                      do_eval=True,\n",
    "#                                      do_predict=True,\n",
    "                                     learning_rate=LEARNING_RATE,\n",
    "                                     num_train_epochs=EPOCHS,\n",
    "                                     save_steps=-1,\n",
    "                                     per_device_train_batch_size = 4)\n",
    "    # Detecting last checkpoint.\n",
    "    last_checkpoint = None\n",
    "    if os.path.isdir(OUTPUT_DIR):\n",
    "        last_checkpoint = get_last_checkpoint(OUTPUT_DIR)\n",
    "        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "            raise ValueError(\n",
    "                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "                \"Use --overwrite_output_dir to overcome.\"\n",
    "            )\n",
    "        elif last_checkpoint is not None:\n",
    "            print(\n",
    "                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "            )\n",
    "\n",
    "    # Set seed before initializing model.\n",
    "    set_seed(SEED)\n",
    "\n",
    "\n",
    "    df = pd.read_csv(DATA_DIR + '/train.tsv', sep='\\t')\n",
    "    df = df.dropna()\n",
    "    train_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "    )\n",
    "    model = AutoModelForPreTraining.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    padding = \"max_length\"\n",
    "\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        texts =(examples['text'],)\n",
    "        result =  tokenizer(*texts, padding=padding, max_length=MAX_SEQUENCE_LENGTH, truncation=True)\n",
    "\n",
    "    train_dataset = train_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        load_from_cache_file=True,\n",
    "        desc=\"Running tokenizer on train dataset\",\n",
    "    )\n",
    "\n",
    "    # Get the metric function\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "    def compute_metrics(p: EvalPrediction):\n",
    "        preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        return metric.compute(predictions=preds, references=p.label_ids)\n",
    "\n",
    "    data_collator = DataCollatorForWholeWordMask(tokenizer=tokenizer)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "#         eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    if training_args.do_train:\n",
    "        checkpoint = None\n",
    "        if training_args.resume_from_checkpoint is not None:\n",
    "            checkpoint = training_args.resume_from_checkpoint\n",
    "        elif last_checkpoint is not None:\n",
    "            checkpoint = last_checkpoint\n",
    "        train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "        metrics = train_result.metrics\n",
    "        max_train_samples = (\n",
    "            len(train_dataset))\n",
    "        metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n",
    "        trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "        trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717bff50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c537df3b63248029f4b496657c5b3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on train dataset:   0%|          | 0/103 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `XLMRobertaForMaskedLM.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `XLMRobertaForMaskedLM.forward`,  you can safely ignore this message.\n",
      "/home/aayush/Documents/TAMU-MS-CS/Sem1/NLP/semeval2023-afrisenti/.venv/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 102966\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 128710\n",
      "/home/aayush/Documents/TAMU-MS-CS/Sem1/NLP/semeval2023-afrisenti/.venv/lib/python3.8/site-packages/transformers/data/data_collator.py:950: UserWarning: DataCollatorForWholeWordMask is only suitable for BertTokenizer-like tokenizers. Please refer to the documentation for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9086' max='128710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  9086/128710 33:35 < 7:22:21, 4.51 it/s, Epoch 0.35/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.049500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.073900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.047400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.050200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.052800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.017500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.014800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.019100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.996400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.971200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.954000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.969800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.970700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetune_lm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb9b66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = f'../models/{LANGUAGE_CODE}'\n",
    "SEED=42\n",
    "OUTPUT_DIR = f\"../models/sentiment/{LANGUAGE_CODE}\"\n",
    "DATA_DIR = f\"../data/raw/train/splitted-train-dev-test/{LANGUAGE_CODE}\"\n",
    "def finetune_sentiment():\n",
    "    \n",
    "    training_args = TrainingArguments(output_dir=OUTPUT_DIR,\n",
    "                                      overwrite_output_dir=True,\n",
    "                                     do_train=True,\n",
    "                                     do_eval=True,\n",
    "                                     do_predict=True,\n",
    "                                     learning_rate=LEARNING_RATE,\n",
    "                                     num_train_epochs=EPOCHS,\n",
    "                                     save_steps=-1,\n",
    "                                     per_device_train_batch_size = 32)\n",
    "    # Detecting last checkpoint.\n",
    "    last_checkpoint = None\n",
    "    if os.path.isdir(OUTPUT_DIR):\n",
    "        last_checkpoint = get_last_checkpoint(OUTPUT_DIR)\n",
    "        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "            raise ValueError(\n",
    "                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "                \"Use --overwrite_output_dir to overcome.\"\n",
    "            )\n",
    "        elif last_checkpoint is not None:\n",
    "            print(\n",
    "                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "            )\n",
    "\n",
    "    # Set seed before initializing model.\n",
    "    set_seed(SEED)\n",
    "\n",
    "\n",
    "    df = pd.read_csv(DATA_DIR + '/train.tsv', sep='\\t')\n",
    "    df = df.dropna()\n",
    "    train_dataset = Dataset.from_pandas(df)\n",
    "    label_list = df['label'].unique().tolist()\n",
    "\n",
    "    df = pd.read_csv(DATA_DIR+ '/dev.tsv', sep='\\t')\n",
    "    df = df.dropna()\n",
    "    eval_dataset = Dataset.from_pandas(df)\n",
    "    label_list = df['label'].unique().tolist()\n",
    "\n",
    "    df = pd.read_csv(DATA_DIR + '/test.tsv', sep='\\t')\n",
    "    df = df.dropna()\n",
    "    predict_dataset = Dataset.from_pandas(df)\n",
    "    label_list = df['label'].unique().tolist()\n",
    "\n",
    "    # Labels\n",
    "    num_labels = len(label_list)\n",
    "    print(label_list)\n",
    "\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=num_labels,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "    )\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    padding = \"max_length\"\n",
    "\n",
    "\n",
    "    # Some models have set the order of the labels to use, so let's make sure we do use it.\n",
    "    label_to_id = None\n",
    "    label_to_id = {v: i for i, v in enumerate(label_list)}\n",
    "\n",
    "    if label_to_id is not None:\n",
    "        model.config.label2id = label_to_id\n",
    "        model.config.id2label = {id: label for label, id in config.label2id.items()}\n",
    "\n",
    "    '''\n",
    "        def preprocess_function(examples):\n",
    "        # Tokenize the texts\n",
    "        return tokenizer(\n",
    "            examples[\"premise\"],\n",
    "            examples[\"hypothesis\"],\n",
    "            padding=padding,\n",
    "            max_length=data_args.max_seq_length,\n",
    "            truncation=True,\n",
    "        )\n",
    "    '''\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        texts =(examples['text'],)\n",
    "        result =  tokenizer(*texts, padding=padding, max_length=MAX_SEQUENCE_LENGTH, truncation=True)\n",
    "        if label_to_id is not None and \"label\" in examples:\n",
    "            result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n",
    "        return result\n",
    "\n",
    "    train_dataset = train_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        load_from_cache_file=True,\n",
    "        desc=\"Running tokenizer on train dataset\",\n",
    "    )\n",
    "    eval_dataset = eval_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        load_from_cache_file=True,\n",
    "        desc=\"Running tokenizer on validation dataset\",\n",
    "    )\n",
    "\n",
    "    predict_dataset = predict_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        load_from_cache_file=not True,\n",
    "        desc=\"Running tokenizer on prediction dataset\",\n",
    "    )\n",
    "\n",
    "    # Get the metric function\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "    def compute_metrics(p: EvalPrediction):\n",
    "        preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        return metric.compute(predictions=preds, references=p.label_ids)\n",
    "\n",
    "    data_collator = default_data_collator\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    if training_args.do_train:\n",
    "        checkpoint = None\n",
    "        if training_args.resume_from_checkpoint is not None:\n",
    "            checkpoint = training_args.resume_from_checkpoint\n",
    "        elif last_checkpoint is not None:\n",
    "            checkpoint = last_checkpoint\n",
    "        train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "        metrics = train_result.metrics\n",
    "        max_train_samples = (\n",
    "            len(train_dataset)\n",
    "        )\n",
    "        metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n",
    "        trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "        trainer.save_state()\n",
    "\n",
    "    # Evaluation\n",
    "    if training_args.do_eval:\n",
    "        print(\"*** Evaluate ***\")\n",
    "        metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "\n",
    "        max_eval_samples = len(eval_dataset)\n",
    "        metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n",
    "\n",
    "        trainer.log_metrics(\"eval\", metrics)\n",
    "        trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "    # Prediction\n",
    "    if training_args.do_predict:\n",
    "        print(\"*** Predict ***\")\n",
    "        predictions, labels, metrics = trainer.predict(predict_dataset, metric_key_prefix=\"predict\")\n",
    "\n",
    "        max_predict_samples = (\n",
    "            len(predict_dataset)\n",
    "        )\n",
    "        metrics[\"predict_samples\"] = min(max_predict_samples, len(predict_dataset))\n",
    "\n",
    "        trainer.log_metrics(\"predict\", metrics)\n",
    "        trainer.save_metrics(\"predict\", metrics)\n",
    "\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        output_predict_file = os.path.join(training_args.output_dir, \"predictions.txt\")\n",
    "        if trainer.is_world_process_zero():\n",
    "            with open(output_predict_file, \"w\") as writer:\n",
    "                writer.write(\"index\\tprediction\\n\")\n",
    "                for index, item in enumerate(predictions):\n",
    "                    item = label_list[item]\n",
    "                    writer.write(f\"{index}\\t{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0431b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c17b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
